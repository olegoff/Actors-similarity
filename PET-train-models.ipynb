{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7eb7a5",
   "metadata": {},
   "source": [
    "В результате подготовительных операций был получен обучающий датасет изображений, который сохранён в папке **train**. Структура датанных разделена на подпапки **men** и **women**, каждая из которых в свою очередь имеет вложенные подпапки **eng** и **rus** для разделения знаменитостей на иностранных и отечественных. Для удобства подобной структуры планируется придерживаться во всём проекте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cac16",
   "metadata": {},
   "source": [
    "Так как в идеале в готовом решении мы хотели бы получить сервис, который по одному загруженному изображению находит максимально похожих иностранных и отечественных знаменитостей, то первая проблема, которую предстоить решить - это автоматическое определение пола по загруженному изображению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6bcf0",
   "metadata": {},
   "source": [
    "Для решения этой задачи необходимо обучить модель на определение пола по загруженному изображению. Для этого необходимо получить и сохранить для каждого изображения эмбединги на основе всё той же библиотеки *face_recognition* и сохранить их с сохранением структуры данных в папке **static**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ddbff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm import notebook\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765c96c",
   "metadata": {},
   "source": [
    "### 1. Получение эмбедингов изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ce039",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция получения и сохранения эмбедингов\n",
    "\n",
    "def get_embedings(gender='men'):  \n",
    "    pet_path = './Documents/DataScience/PET-project'\n",
    "    \n",
    "    # Создание папки для хранения эмбедингов\n",
    "    if os.path.exists(f'{pet_path}/static') != True:\n",
    "        os.mkdir(f'{pet_path}/static')\n",
    "        \n",
    "    # Создание подпапок для актеров и актрис\n",
    "    if os.path.exists(f'{pet_path}/static/{gender}') != True:\n",
    "        os.mkdir(f'{pet_path}/static/{gender}')\n",
    "        \n",
    "    nation = ['eng', 'rus']\n",
    "    for natio in nation:\n",
    "        # Создание подпапок для разделения знаменитостей на иностранных и отечественных\n",
    "        if os.path.exists(f'{pet_path}/static/{gender}/{natio}') != True:\n",
    "            os.mkdir(f'{pet_path}/static/{gender}/{natio}')\n",
    "        \n",
    "        # Получаем список знаменитостей из папки train\n",
    "        folders = glob.glob(f'{pet_path}/train/{gender}/{natio}/*')\n",
    "        \n",
    "        dict_labels = dict()\n",
    "        for i, name in enumerate(folders):\n",
    "            if natio == 'eng':\n",
    "                name = name[name.find('eng\\\\') + 4:].strip()\n",
    "            elif natio == 'rus':\n",
    "                name = name[name.find('rus\\\\') + 4:].strip()\n",
    "            dict_labels[name] = i\n",
    "        \n",
    "        # Сохранение словаря с метками\n",
    "        pkl_patch = f'{pet_path}/static/'\n",
    "        \n",
    "        if gender == 'men':\n",
    "            role = 'actors'\n",
    "        elif gender == 'women':\n",
    "            role = 'actresses'\n",
    "        \n",
    "        with open(pkl_patch + f'{natio}-{role}-dict-labels.pkl','wb') as f:\n",
    "            pickle.dump(dict_labels, f)\n",
    "        \n",
    "        # Создаём пустые массивы под эмбеддинги и метки\n",
    "        embedings = np.empty(128)\n",
    "        target = []\n",
    "        \n",
    "        for person in notebook.tqdm(list(dict_labels.keys())):\n",
    "            images = os.listdir(f'{pet_path}/train/{gender}/{natio}/{person}')\n",
    "            \n",
    "            for num, person_img in enumerate(images):\n",
    "                face = face_recognition.load_image_file(f'{pet_path}/train/{gender}/{natio}/{person}/{person_img}')\n",
    "                try:\n",
    "                    # Преобразуем фото с лицом в вектор, получаем embeding\n",
    "                    face_enc = face_recognition.face_encodings(face)[0]\n",
    "                    \n",
    "                    # Добавляем в датасет матрицу\n",
    "                    embedings = np.vstack((embedings, face_enc))\n",
    "                    \n",
    "                    # Добавляем таргет по текущему индексу\n",
    "                    target.append(dict_labels[person])\n",
    "                except Exception as ex:\n",
    "                    print(f'Error message {ex}')\n",
    "                    \n",
    "            print(f'Embeding for :: {person} - successfully received !')\n",
    "        \n",
    "        # Удаляем из датасета первый элемент, так как это пустая матрица\n",
    "        embedings_ = embedings[1:]\n",
    "        \n",
    "        with open(f'{pet_path}/static/{gender}/{natio}/' + 'embedings-train.pkl','wb') as f:\n",
    "            pickle.dump(embedings_, f)\n",
    "        \n",
    "        with open(f'{pet_path}/static/{gender}/{natio}/' + 'labels-train.pkl','wb') as f:\n",
    "            pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d746e4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_embedings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cdb65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_embedings(gender='women')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d708be7",
   "metadata": {},
   "source": [
    "### 2. Обучение модели для определения пола по загруженному изображению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfd86b",
   "metadata": {},
   "source": [
    "После того, как получены эмбединги обучим модель для определения пола по загруженному изображению. В качестве бейзлайна попробуем использовать линенейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162df06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция для считывания сохраненных эмбедингов\n",
    "\n",
    "def read_embedings(gender='men'):\n",
    "    stat_path = './Documents/DataScience/PET-project/static'\n",
    "    \n",
    "    nation = ['eng', 'rus']\n",
    "    target = []\n",
    "    for natio in nation:\n",
    "        with open(f'{stat_path}/{gender}/{natio}/embedings-train.pkl','rb') as f:\n",
    "            if natio == 'eng':\n",
    "                embedings = pickle.load(f)\n",
    "            else:\n",
    "                embedings = np.concatenate((embedings, pickle.load(f)), axis=0)\n",
    "        \n",
    "        with open(f'{stat_path}/{gender}/{natio}/labels-train.pkl','rb') as f:\n",
    "            target += pickle.load(f)\n",
    "    \n",
    "    return (embedings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752116d1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем эмбединги и метки для женщин в переменных\n",
    "\n",
    "read_embedings_women = read_embedings(gender='women')\n",
    "embedings_women = read_embedings_women[0]\n",
    "target_women = read_embedings_women[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3eab1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток для женщин\n",
    "\n",
    "len(embedings_women), len(target_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b59b89",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем эмбединги и метки для мужчин в переменных\n",
    "\n",
    "read_embedings_men = read_embedings()\n",
    "embedings_men = read_embedings_men[0]\n",
    "target_men = read_embedings_men[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37b8bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток для мужчин\n",
    "\n",
    "len(embedings_men), len(target_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f61a15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Объединяем метки мужчин и женщин пометив всех женщин 1, а всех мужчин 0. также объединяем их эмбединги. Ещё раз проверяем\n",
    "# количество.\n",
    "\n",
    "target = [1 for i in target_women] + [0 for i in target_men]\n",
    "embedings = np.concatenate((embedings_women, embedings_men), axis=0)\n",
    "len(embedings), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5100d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сплитим датасет на тренировочную и проверочную части\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedings, target, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705709c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e97f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, model.predict(X_test))\n",
    "print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f16cf8",
   "metadata": {},
   "source": [
    "F-мера для обученной модели на определение пола приближается к 100%. Поэтому, считаем задача определения пола решена. Сохраняем обученную модель для последующего использования в продакшине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc105b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_patch = './Documents/DataScience/PET-project/static/models'\n",
    "\n",
    "if os.path.exists(pkl_patch) != True:\n",
    "    os.mkdir(pkl_patch)\n",
    "\n",
    "with open(f'{pkl_patch}/model_gender_determination.pkl','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c1802",
   "metadata": {},
   "source": [
    "Далее обучим модели на поиск лиц по имеющемуся в папке **target** датасету."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f75c0",
   "metadata": {},
   "source": [
    "### 3. Обучение моделей на распознавание лиц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0760844",
   "metadata": {},
   "source": [
    "Согласно поставленной задаче необходимо обучить четыре модели:\n",
    "* иностранных актёров;\n",
    "* отечественных актёров;\n",
    "* иностранных актрис;\n",
    "* отечественных актрис.\n",
    "\n",
    "Обученные модели сохранить для последующего использования в продакшине."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a99b6",
   "metadata": {},
   "source": [
    "#### Модель для иностранных актёров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4e118",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подгрузим сохранённые эмбединги иностранных актёров для считывания\n",
    "\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/men/eng'\n",
    "\n",
    "with open(f'{pkl_patch}/embedings-train.pkl','rb') as f:\n",
    "    embedings_ = pickle.load(f)\n",
    "    \n",
    "with open(f'{pkl_patch}/labels-train.pkl','rb') as f:\n",
    "    target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae16dac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток\n",
    "\n",
    "embedings_.shape, len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90e318",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция поиска индексов знаменитостей с одним изображеним\n",
    "less_one = []\n",
    "\n",
    "for index in range(len(target)):\n",
    "    cnt = target.count(target[index])\n",
    "    if cnt < 2:\n",
    "        less_one.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969adf76",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаление знаменитостей с одним изображением из эмбедингов и таргетов\n",
    "\n",
    "embedings = []\n",
    "for index in range(len(embedings_)):\n",
    "    if index not in less_one:\n",
    "        embedings.append(embedings_[index])\n",
    "        \n",
    "target_ = []\n",
    "for index in range(len(target)):\n",
    "    if index not in less_one:\n",
    "        target_.append(target[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf775e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4bb8b5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сплитим датасет на тренировочную и проверочную части\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedings, target_, test_size=0.25, stratify=target_, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33a047",
   "metadata": {},
   "source": [
    "Линейную регрессию будем использовать с решающим алгоритмом *solver='liblinear'* и коэффициентом регуляризации *C=50*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5b0b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression(solver='liblinear', C=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f27e46",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, model.predict(X_test), average='micro')\n",
    "print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138cde5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "\"\"\"\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/models'\n",
    "\n",
    "with open(f'{pkl_patch}/eng_actors.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79819566",
   "metadata": {},
   "source": [
    "#### Модель для отечественных актёров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dae04f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подгрузим сохранённые эмбединги отечественных актёров для считывания\n",
    "\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/men/rus'\n",
    "\n",
    "with open(f'{pkl_patch}/embedings-train.pkl','rb') as f:\n",
    "    embedings_ = pickle.load(f)\n",
    "    \n",
    "with open(f'{pkl_patch}/labels-train.pkl','rb') as f:\n",
    "    target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b0e7e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток\n",
    "\n",
    "embedings_.shape, len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6064149",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция поиска индексов знаменитостей с одним изображеним\n",
    "less_one = []\n",
    "\n",
    "for index in range(len(target)):\n",
    "    cnt = target.count(target[index])\n",
    "    if cnt < 2:\n",
    "        less_one.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58acb16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаление знаменитостей с одним изображением из эмбедингов и таргетов\n",
    "\n",
    "embedings = []\n",
    "for index in range(len(embedings_)):\n",
    "    if index not in less_one:\n",
    "        embedings.append(embedings_[index])\n",
    "        \n",
    "target_ = []\n",
    "for index in range(len(target)):\n",
    "    if index not in less_one:\n",
    "        target_.append(target[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b71f8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сплитим датасет на тренировочную и проверочную части\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedings, target_, test_size=0.275, stratify=target_, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfc993",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression(solver='liblinear', C=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c36d83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, model.predict(X_test), average='micro')\n",
    "print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf6da1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "\"\"\"\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/models'\n",
    "\n",
    "with open(f'{pkl_patch}/rus_actors.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea80d2",
   "metadata": {},
   "source": [
    "#### Модель для иностранных актрис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5b808",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подгрузим сохранённые эмбединги иностранных актрис для считывания\n",
    "\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/women/eng'\n",
    "\n",
    "with open(f'{pkl_patch}/embedings-train.pkl','rb') as f:\n",
    "    embedings_ = pickle.load(f)\n",
    "    \n",
    "with open(f'{pkl_patch}/labels-train.pkl','rb') as f:\n",
    "    target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034477",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток\n",
    "\n",
    "embedings_.shape, len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba74ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция поиска индексов знаменитостей с одним изображеним\n",
    "less_one = []\n",
    "\n",
    "for index in range(len(target)):\n",
    "    cnt = target.count(target[index])\n",
    "    if cnt < 2:\n",
    "        less_one.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1dbd4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаление знаменитостей с одним изображением из эмбедингов и таргетов\n",
    "\n",
    "embedings = []\n",
    "for index in range(len(embedings_)):\n",
    "    if index not in less_one:\n",
    "        embedings.append(embedings_[index])\n",
    "        \n",
    "target_ = []\n",
    "for index in range(len(target)):\n",
    "    if index not in less_one:\n",
    "        target_.append(target[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4766a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сплитим датасет на тренировочную и проверочную части\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedings, target_, test_size=0.25, stratify=target_, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ec6d1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression(solver='liblinear', C=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7bf4e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, model.predict(X_test), average='micro')\n",
    "print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d445f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "\"\"\"\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/models'\n",
    "\n",
    "with open(f'{pkl_patch}/eng_actresses.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe346c",
   "metadata": {},
   "source": [
    "#### Модель для отечественных актрис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36298b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подгрузим сохранённые эмбединги отечественных актрис для считывания\n",
    "\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/women/rus'\n",
    "\n",
    "with open(f'{pkl_patch}/embedings-train.pkl','rb') as f:\n",
    "    embedings_ = pickle.load(f)\n",
    "    \n",
    "with open(f'{pkl_patch}/labels-train.pkl','rb') as f:\n",
    "    target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de684f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверяем соотвествие количества эмбедингов и меток\n",
    "\n",
    "embedings_.shape, len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd09a34",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция поиска индексов знаменитостей с одним изображеним\n",
    "less_one = []\n",
    "\n",
    "for index in range(len(target)):\n",
    "    cnt = target.count(target[index])\n",
    "    if cnt < 2:\n",
    "        less_one.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c401fea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721708f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаление знаменитостей с одним изображением из эмбедингов и таргетов\n",
    "\n",
    "embedings = []\n",
    "for index in range(len(embedings_)):\n",
    "    if index not in less_one:\n",
    "        embedings.append(embedings_[index])\n",
    "        \n",
    "target_ = []\n",
    "for index in range(len(target)):\n",
    "    if index not in less_one:\n",
    "        target_.append(target[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8198e56",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сплитим датасет на тренировочную и проверочную части\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedings, target_, test_size=0.275, stratify=target_, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448567a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression(solver='liblinear', C=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7685e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, model.predict(X_test), average='micro')\n",
    "print(f'F1 score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb85921",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "\"\"\"\n",
    "pkl_patch = './Documents/DataScience/PET-project/static/models'\n",
    "\n",
    "with open(f'{pkl_patch}/rus_actresses.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a234e6d",
   "metadata": {},
   "source": [
    "После обучения F-мера для модели иностранных актёров составила 96,19%, для отечественных актёров - 96,56%, для иностранных актрис - 96,42%, для отечественных актрис - 97,17%. Будем использовать эти модели в продакшине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c69ec9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
