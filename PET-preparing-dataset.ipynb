{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73f5c3b",
   "metadata": {},
   "source": [
    "После загрузки изображений с сайта Кинопоиск получены три папки: **sample_dataset**, в которой хранятся единичные качественные изображения знаменитостей, которые могут быть использованы в качестве эталонных; **gallery**, в которой могут находится до пяти дополнительных изображений; **images**, в которой также содержится некоторое количество дополнительных изображений. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b8f48",
   "metadata": {},
   "source": [
    "Дополнительные изображения разного качества. Для очень популярных знаменитостей их количество в папке **images** может достигать нескольких сотен. Поэтому, целесообразно отобрать из них наиболее релевантные изображения лица для каждой знаменитости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd2269",
   "metadata": {},
   "source": [
    "Для этого создадим фнукцию, которая возьмёт список знаменитостей из папки **sample_dataset** и, сохрнаяя разеление знаменитостей на отечественных и иностранных, получит доступные дополнительные изображения для каждой знаменитости. Для каждого дополнительного изображения будет вычислен эмбединг на основе библиотеки *face_recognition* и сопоставлен с эмбедином эталонных изображений. По косинусному расстоянию между эмбедингом эталонного изображения и эмбедигами остальных изображений будет произведён отбор наиболее релевантных изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b581f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import notebook\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil\n",
    "import os, sys\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdefadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b449f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция отбора изображений для обучающего датасета\n",
    "\n",
    "def selection_images(gender='men'):\n",
    "    pet_path = './Documents/DataScience/PET-project'\n",
    "    \n",
    "    # Создание папки под финальный датасет\n",
    "    if os.path.exists(f'{pet_path}/train') != True:\n",
    "        os.mkdir(f'{pet_path}/train')\n",
    "    \n",
    "    # Создание подпапок для актеров и актрис\n",
    "    if os.path.exists(f'{pet_path}/train/{gender}') != True:\n",
    "        os.mkdir(f'{pet_path}/train/{gender}')\n",
    "    \n",
    "    nation = ['eng', 'rus']\n",
    "    for natio in nation:\n",
    "        # Создание подпапок для разделения знаменитостей на иностранных и отечественных\n",
    "        if os.path.exists(f'{pet_path}/train/{gender}/{natio}') != True:\n",
    "            os.mkdir(f'{pet_path}/train/{gender}/{natio}')\n",
    "        \n",
    "        # Получаем список знаменитостей из папки с эталонными изображениями\n",
    "        folders = glob.glob(f'{pet_path}/sample_dataset/{gender}/{natio}/*')\n",
    "                            \n",
    "        # Производим перебор списка знаменитостей с отбором наилучших изображений\n",
    "        for folder in notebook.tqdm(folders):\n",
    "            if natio == 'eng':\n",
    "                name = folder[folder.find('eng\\\\') + 4:].strip()\n",
    "            elif natio == 'rus':\n",
    "                name = folder[folder.find('rus\\\\') + 4:].strip()\n",
    "            \n",
    "            if os.path.exists(f'{pet_path}/train/{gender}/{natio}/{name}') != True:\n",
    "                os.mkdir(f'{pet_path}/train/{gender}/{natio}/{name}')\n",
    "                print(f'Directory for {name} created!')\n",
    "            else:\n",
    "                print(f'Images for {name} already uploaded!')\n",
    "                continue\n",
    "            \n",
    "            # Путь к эталонным изображениям\n",
    "            path_to_sample = f'{pet_path}/sample_dataset'\n",
    "            \n",
    "            # Путь к галерее дополнтельных изображений знаменитостей\n",
    "            path_to_gallery = f'{pet_path}/gallery'\n",
    "            \n",
    "            # Путь к расширенному набору изображений знаменитостей\n",
    "            path_to_images = f'{pet_path}/images'\n",
    "            \n",
    "            # Формируем список файлов для последующего отбора\n",
    "            sample_file = os.listdir(f'{path_to_sample}/{gender}/{natio}/{name}')\n",
    "            files =  [f'{path_to_sample}/{gender}/{natio}/{name}/' + file for file in sample_file]\n",
    "            \n",
    "            try:\n",
    "                gallery_files = os.listdir(f'{path_to_gallery}/{gender}/{natio}/{name}')\n",
    "                [files.append(f'{path_to_gallery}/{gender}/{natio}/{name}/' + file) for file in gallery_files if \\\n",
    "                os.stat(f'{path_to_gallery}/{gender}/{natio}/{name}/' + file).st_size > 0]\n",
    "                \n",
    "                images_files = os.listdir(f'{path_to_images}/{gender}/{natio}/{name}')\n",
    "                [files.append(f'{path_to_images}/{gender}/{natio}/{name}/' + file) for file in images_files if \\\n",
    "                os.stat(f'{path_to_images}/{gender}/{natio}/{name}/' + file).st_size > 0]\n",
    "            except FileNotFoundError:\n",
    "                try:\n",
    "                    print(f'Path :: {path_to_gallery}/{gender}/{natio}/{name} - not found!')\n",
    "                    shutil.copy(f'{path_to_sample}/{gender}/{natio}/{name}/256.jpg',\\\n",
    "                                f'{pet_path}/train/{gender}/{natio}/{name}/Image_0.jpg')\n",
    "                except FileNotFoundError:\n",
    "                    print(f'File :: {path_to_sample}/{gender}/{natio}/{name}/256.jpg - not found!')\n",
    "                    continue\n",
    "                continue\n",
    "            \n",
    "            # Вычисляем эмбединги для лиц на каждом изображении\n",
    "            embedings = []\n",
    "            for file in files:\n",
    "                try:\n",
    "                    sample_face = face_recognition.load_image_file(file)\n",
    "                    embedings.append(face_recognition.face_encodings(sample_face)[0])\n",
    "                except (IndexError, UnidentifiedImageError):\n",
    "                    print(f'Not found face in {file}')\n",
    "                    continue\n",
    "            \n",
    "            if len(embedings) > 1:\n",
    "                # Группировка изображений по кластерам для последующего отбора\n",
    "                agg = AgglomerativeClustering(n_clusters=None, distance_threshold=0.1,\\\n",
    "                                              affinity='cosine', linkage='complete').fit(embedings)\n",
    "                \n",
    "                # Сохраняем в переменных полученные лейблы и количество классов\n",
    "                labels = agg.labels_\n",
    "                n_classes = len(set(labels))\n",
    "                \n",
    "                # Разбираем файлы по полученным группам\n",
    "                files_by_group = [[] for x in range(n_classes)]\n",
    "                \n",
    "                for x in range(n_classes):\n",
    "                    for j in range(len(labels)):\n",
    "                        if labels[j] == x:\n",
    "                            files_by_group[x].append(files[j])\n",
    "                            \n",
    "                # Определяем самый большой кластер\n",
    "                max_labels_count = 0\n",
    "                \n",
    "                for x in range(1, n_classes):\n",
    "                    if len(files_by_group[x]) > len(files_by_group[max_labels_count]):\n",
    "                        max_labels_count = x\n",
    "                        \n",
    "                # Находим в какой кластер попало эталонное изображение\n",
    "                group_with_sample = 0\n",
    "                \n",
    "                for x in range(n_classes):\n",
    "                    if f'{path_to_sample}/{gender}/{natio}/{name}/256.jpg' in files_by_group[x]:\n",
    "                        group_with_sample = x\n",
    "                        break\n",
    "                        \n",
    "                # Формируем словарь с ключами в виде имени файла и значениями в виде эмбедингов\n",
    "                dictionary = dict(zip(files, embedings))\n",
    "                \n",
    "                # Проверяем совпадает ли номер наибольшего кластера с номером кластера, в котором обнаружено эталонное \n",
    "                # изображение. Если нет - то объединяем эти два кластера.\n",
    "                if max_labels_count == group_with_sample:\n",
    "                    main_files = files_by_group[max_labels_count]\n",
    "                else:\n",
    "                    main_files = files_by_group[group_with_sample] + files_by_group[max_labels_count]\n",
    "                    \n",
    "                # Вычисляем косинусное расстояние, сохраняем его в словарь и по нему отбираем наилучшие файлы как наиболее\n",
    "                # близкие к эталонному изображению\n",
    "                rates = dict()\n",
    "                \n",
    "                for f in main_files[1:]:\n",
    "                    sample_key = f'{path_to_sample}/{gender}/{natio}/{name}/256.jpg'\n",
    "                    cos = cosine_similarity(dictionary[sample_key].reshape(1, -1), dictionary[f].reshape(1, -1))[0][0]\n",
    "                    rates[cos] = f\n",
    "                    \n",
    "                sorted_rates = list(rates.keys())\n",
    "                sorted_rates.sort(reverse=True)\n",
    "                \n",
    "                best_images = [rates[x] for x in sorted_rates if 0.99 > x > 0.93]\n",
    "                \n",
    "                # Рекурсивная функция для удаления дубликатов из отобранных изображений\n",
    "                def doubles_cleaner(images, pos, dictionary=dictionary):\n",
    "                    if pos == len(images)-1:\n",
    "                        return(images)\n",
    "                    else:\n",
    "                        for x in range(pos+1, len(images)):\n",
    "                            if cosine_similarity(dictionary[images[pos]].reshape(1, -1),\\\n",
    "                                                 dictionary[images[x]].reshape(1, -1))[0] > 0.98:\n",
    "                                del images[x]\n",
    "                                return doubles_cleaner(images, pos=pos+1)\n",
    "                            return doubles_cleaner(images, pos=pos+1)\n",
    "                        \n",
    "                try:\n",
    "                    doubles_cleaner(best_images, pos=0)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Добавляем в начало списка отобранных файлов эталонное изображение\n",
    "                best_images.insert(0, sample_key)\n",
    "                \n",
    "                # сохранение полученных изображений в итоговый тренировочный датасет\n",
    "                i = 0\n",
    "                for best_image in best_images:\n",
    "                    shutil.copy(best_image, f'{pet_path}/train/{gender}/{natio}/{name}/Image_{i}.jpg')\n",
    "                    i += 1\n",
    "            else:\n",
    "                try:\n",
    "                    shutil.copy(f'{path_to_sample}/{gender}/{natio}/{name}/256.jpg',\\\n",
    "                                f'{pet_path}/train/{gender}/{natio}/{name}/Image_0.jpg')\n",
    "                except FileNotFoundError:\n",
    "                    print(f'File :: {path_to_sample}/{gender}/{natio}/{name}/256.jpg - not found!')\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca982e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_images(gender='women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d98d89",
   "metadata": {},
   "source": [
    "Изображения отобраны. Визуальный анализ сохранённых изображений показал, что разброс количества фотографий лиц для отдельных знаменитостей все ещё велик и находится в диапазоне от ноля до полутора сотен. Поэтому, чтобы избежать такого дисбаланса, произведём следующее:\n",
    "* удалим всех знаменитостей, у которых число изображений менее двух;\n",
    "* ограничим максимальное число изображений 25 фотографими лиц для каждой знаменитости, удалив лишние в конце списка.\n",
    "\n",
    "Напишем для этого соотвествующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для удаления лишних изображений\n",
    "\n",
    "def deleting_excess_images(gender='men'):\n",
    "    train_path = './Documents/DataScience/PET-project'\n",
    "    \n",
    "    nation = ['eng', 'rus']\n",
    "    for natio in nation:\n",
    "        # Получаем список знаменитостей\n",
    "        folders = glob.glob(f'{train_path}/train/{gender}/{natio}/*')\n",
    "        \n",
    "        # Производим перебор списка знаменитостей\n",
    "        for folder in notebook.tqdm(folders):\n",
    "            if natio == 'eng':\n",
    "                name = folder[folder.find('eng\\\\') + 4:].strip()\n",
    "            elif natio == 'rus':\n",
    "                name = folder[folder.find('rus\\\\') + 4:].strip()\n",
    "                \n",
    "            # Получаем список изображений для каждой знаменитости\n",
    "            try:\n",
    "                files = glob.glob(f'{train_path}/train/{gender}/{natio}/{name}/*')\n",
    "                \n",
    "                # Оставим только папки с количеством изображений 2 и более, а также если файлов больше 25 в папке, \n",
    "                # о оставляем только 25, первых, а остальные удаляем\n",
    "                if len(files) < 2:\n",
    "                    shutil.rmtree(f'{train_path}/train/{gender}/{natio}/{name}/', ignore_errors=True)\n",
    "                    print(f'Directory :: {train_path}/train/{gender}/{natio}/{name}/ contains less that 2 images and deleted!')\n",
    "                elif len(files) > 25:\n",
    "                    # Получаем уникальные номера изображений в папках знаменитостей\n",
    "                    file_numbers = []\n",
    "                    for file in files:\n",
    "                        f_name = file.split('\\\\')[-1]\n",
    "                        file_numbers.append(int(f_name.replace('Image_', '').replace('.jpg', '')))\n",
    "                        \n",
    "                    # Сортировка списка\n",
    "                    file_numbers.sort()\n",
    "                    \n",
    "                    # Получаем идентификаторы файлов для удаления\n",
    "                    del_files = file_numbers[25:]\n",
    "\n",
    "                    # Удаляем файлы\n",
    "                    for num in del_files:\n",
    "                         os.remove(f'{train_path}/train/{gender}/{natio}/{name}/Image_{str(num)}.jpg')\n",
    "                    print(f'Excess images in folder :: {train_path}/train/{gender}/{natio}/{name} - successful deleted!')\n",
    "            except FileNotFoundError:\n",
    "                print(f'Path :: {train_path}/train/{gender}/{natio}/{name} - not found!')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a43756",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleting_excess_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleting_excess_images(gender='women')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64fc5",
   "metadata": {},
   "source": [
    "На этом подготовку обучающих датсетов можно считать завершенной и перейти к обучению моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b08bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
